{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from formats import experiment_pb2\n",
    "from formats import  quantification_pb2\n",
    "\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, ChainDataset\n",
    "\n",
    "\n",
    "import os\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer.autoguide.guides import AutoDiagonalNormal\n",
    "import pyro.distributions.constraints as constraints\n",
    "from tqdm import trange\n",
    "\n",
    "import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_radius_px = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    }
   ],
   "source": [
    "import data\n",
    "dataset = data.get_dataset(local_radius_px=local_radius_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,q = next(iter(torch.utils.data.DataLoader(dataset=dataset,batch_size=len(dataset))))\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# x_shape = x.shape\n",
    "# x = StandardScaler().fit_transform(x.reshape(-1,x.shape[-1])).reshape(x_shape)\n",
    "# q = StandardScaler().fit_transform(q)\n",
    "\n",
    "# x = torch.Tensor(x)\n",
    "# q = torch.Tensor(q)\n",
    "\n",
    "x /= x.shape[1]*x.shape[2]/q.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_reconstruction(reconstruction):\n",
    "    x_hat, q_hat = reconstruction\n",
    "    \n",
    "    x_flat = x.reshape(-1,x.shape[-1])\n",
    "    x_hat = x_hat.reshape(-1,x.shape[-1])\n",
    "\n",
    "    x_mean = x_flat.mean(0)\n",
    "    x_ssr = (x_flat - x_hat).pow(2).sum()\n",
    "    x_sst = (x_flat - x_mean).pow(2).sum()\n",
    "    x_r2 = 1 - x_ssr/x_sst\n",
    "\n",
    "    q_mean = q.mean(0)\n",
    "    q_ssr = (q - q_hat).pow(2).sum()\n",
    "    q_sst = (q - q_mean).pow(2).sum()\n",
    "    q_r2 = 1 - q_ssr/q_sst\n",
    "\n",
    "    return x_r2.item(), q_r2.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_pca_reconstruct(n_components):\n",
    "    combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(combined_data)\n",
    "    recon = torch.tensor(pca.inverse_transform(pca.transform(combined_data)))\n",
    "\n",
    "    q_hat = recon[:,:q.shape[1]] \n",
    "    x_hat = recon[:,q.shape[1]:].reshape(x.shape) \n",
    "    \n",
    "    return x_hat, q_hat\n",
    "\n",
    "def joint_pca_latents(n_components):\n",
    "    combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7374055943106592, 0.02206323675223343)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7524027768391566, 0.4358681221488049)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7528608619827024, 0.6393485737060141)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0.7521909570466426, 0.007489184130836213)\n",
      "(0.8437800360955272, 0.021052586212242264)\n",
      "(0.8685366549539695, 0.02139881718012482)\n",
      "\n",
      "6\n",
      "(0.7521883019714131, 0.007591373151785041)\n",
      "(0.8436717229891644, 0.02488976069652027)\n",
      "(0.8679818350784987, 0.03532927028618282)\n",
      "\n",
      "11\n",
      "(0.7521578249474512, 0.007863951067025754)\n",
      "(0.8369275961995328, 0.07463169287954674)\n",
      "(0.8432360017169178, 0.4515279940855007)\n",
      "\n",
      "16\n",
      "(0.7520161709634988, 0.008390531842191296)\n",
      "(0.7571769271880807, 0.42675407091754725)\n",
      "(0.8351439874557265, 0.47973636196687064)\n",
      "\n",
      "21\n",
      "(0.7515017974469874, 0.009419862670241197)\n",
      "(0.754019660806886, 0.43406425820223127)\n",
      "(0.7601663659860601, 0.6292715548553929)\n",
      "\n",
      "26\n",
      "(0.7494782243654843, 0.011924167623012183)\n",
      "(0.7531694514303244, 0.43519132738531474)\n",
      "(0.7538540881642922, 0.6384588602622177)\n",
      "\n",
      "31\n",
      "(0.7357511333563822, 0.023296996180023566)\n",
      "(0.7523588116682863, 0.43590088237697233)\n",
      "(0.7528147108263997, 0.6393829649136819)\n",
      "\n",
      "36\n",
      "(0.31912898525382294, 0.26980568723984155)\n",
      "(0.751100248455126, 0.43669248480436396)\n",
      "(0.7516304156092994, 0.6401310441232096)\n",
      "\n",
      "41\n",
      "(0.028327867112996175, 0.41939866130936077)\n",
      "(0.748753174696341, 0.43780682412329586)\n",
      "(0.7497682740411065, 0.6410188681374406)\n",
      "\n",
      "46\n",
      "(0.011799977799366701, 0.4258347229351903)\n",
      "(0.7428444655193417, 0.43998632433483964)\n",
      "(0.7465487061110584, 0.6422196931756016)\n",
      "\n",
      "51\n",
      "(0.007663786043057286, 0.4271110596952048)\n",
      "(0.6621385392501155, 0.46307749292704925)\n",
      "(0.7395824874336385, 0.6442956782211775)\n",
      "\n",
      "56\n",
      "(0.005938848166681443, 0.42754553351321745)\n",
      "(0.023560977585277643, 0.6278756953027858)\n",
      "(0.4173579184030667, 0.7191934974258556)\n",
      "\n",
      "61\n",
      "(0.005026843253235547, 0.4277369477279155)\n",
      "(0.00949284026792585, 0.6308954125470857)\n",
      "(0.018272114738595913, 0.8075690311966424)\n",
      "\n",
      "66\n",
      "(0.004474551433305551, 0.42783515695555974)\n",
      "(0.0068489623402535615, 0.6313691979471332)\n",
      "(0.012070982373502681, 0.8086868399009774)\n",
      "\n",
      "71\n",
      "(0.004108791132858114, 0.42789091120741074)\n",
      "(0.005746400594361045, 0.631537944352315)\n",
      "(0.010168283602897454, 0.8089785776777941)\n",
      "\n",
      "76\n",
      "(0.0038518595303450587, 0.42792494102828027)\n",
      "(0.005133869478566311, 0.6316191884137725)\n",
      "(0.009213985448570772, 0.8091052244589695)\n",
      "\n",
      "81\n",
      "(0.0036625547966259164, 0.4279468771343179)\n",
      "(0.004741095863753264, 0.6316647624253894)\n",
      "(0.0086294137981614, 0.8091730788219158)\n",
      "\n",
      "86\n",
      "(0.0035184151989270385, 0.4279616356628978)\n",
      "(0.004467457263023666, 0.6316928007613316)\n",
      "(0.008231271504549609, 0.8092138809358741)\n",
      "\n",
      "91\n",
      "(0.003405707936880664, 0.42797191398317835)\n",
      "(0.004266121951044033, 0.6317111625000625)\n",
      "(0.007941746523341786, 0.8092402832449983)\n",
      "\n",
      "96\n",
      "(0.003315308153499452, 0.42797927920563006)\n",
      "(0.004111794461470364, 0.6317237479945348)\n",
      "(0.007721304875709545, 0.8092582657231447)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for norm_factor in np.arange(1,100,5):\n",
    "    x /= norm_factor\n",
    "\n",
    "    def eval_reconstruction(reconstruction):\n",
    "        x_hat, q_hat = reconstruction\n",
    "        \n",
    "        x_flat = x.reshape(-1,x.shape[-1])\n",
    "        x_hat = x_hat.reshape(-1,x.shape[-1])\n",
    "\n",
    "        x_mean = x_flat.mean(0)\n",
    "        x_ssr = (x_flat - x_hat).pow(2).sum()\n",
    "        x_sst = (x_flat - x_mean).pow(2).sum()\n",
    "        x_r2 = 1 - x_ssr/x_sst\n",
    "\n",
    "        q_mean = q.mean(0)\n",
    "        q_ssr = (q - q_hat).pow(2).sum()\n",
    "        q_sst = (q - q_mean).pow(2).sum()\n",
    "        q_r2 = 1 - q_ssr/q_sst\n",
    "\n",
    "        return x_r2.item(), q_r2.item()\n",
    "\n",
    "    def joint_pca_reconstruct(n_components):\n",
    "        combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(combined_data)\n",
    "        recon = torch.tensor(pca.inverse_transform(pca.transform(combined_data)))\n",
    "\n",
    "        q_hat = recon[:,:q.shape[1]] \n",
    "        x_hat = recon[:,q.shape[1]:].reshape(x.shape) \n",
    "        \n",
    "        return x_hat, q_hat\n",
    "\n",
    "    def joint_pca_latents(n_components):\n",
    "        combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        return pca.fit_transform(combined_data)\n",
    "    \n",
    "    print(norm_factor)\n",
    "    print(eval_reconstruction(joint_pca_reconstruct(n_components=1)))\n",
    "    print(eval_reconstruction(joint_pca_reconstruct(n_components=2)))\n",
    "    print(eval_reconstruction(joint_pca_reconstruct(n_components=3)))\n",
    "    print()\n",
    "    x *= norm_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
