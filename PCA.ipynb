{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from formats import experiment_pb2\n",
    "from formats import  quantification_pb2\n",
    "\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, ChainDataset\n",
    "\n",
    "\n",
    "import os\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer.autoguide.guides import AutoDiagonalNormal\n",
    "import pyro.distributions.constraints as constraints\n",
    "from tqdm import trange\n",
    "\n",
    "import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_radius_px = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "dataset = data.get_dataset(local_radius_px=local_radius_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,q = next(iter(torch.utils.data.DataLoader(dataset=dataset,batch_size=len(dataset))))\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# x_shape = x.shape\n",
    "# x = StandardScaler().fit_transform(x.reshape(-1,x.shape[-1])).reshape(x_shape)\n",
    "# q = StandardScaler().fit_transform(q)\n",
    "\n",
    "# x = torch.Tensor(x)\n",
    "# q = torch.Tensor(q)\n",
    "\n",
    "x /= x.shape[1]*x.shape[2]/q.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_reconstruction(reconstruction):\n",
    "    x_hat, q_hat = reconstruction\n",
    "    \n",
    "    x_flat = x.reshape(-1,x.shape[-1])\n",
    "    x_hat = x_hat.reshape(-1,x.shape[-1])\n",
    "\n",
    "    x_mean = x_flat.mean(0)\n",
    "    x_ssr = (x_flat - x_hat).pow(2).sum()\n",
    "    x_sst = (x_flat - x_mean).pow(2).sum()\n",
    "    x_r2 = 1 - x_ssr/x_sst\n",
    "\n",
    "    q_mean = q.mean(0)\n",
    "    q_ssr = (q - q_hat).pow(2).sum()\n",
    "    q_sst = (q - q_mean).pow(2).sum()\n",
    "    q_r2 = 1 - q_ssr/q_sst\n",
    "\n",
    "    return x_r2.item(), q_r2.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_pca_reconstruct(n_components):\n",
    "    combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(combined_data)\n",
    "    recon = torch.tensor(pca.inverse_transform(pca.transform(combined_data)))\n",
    "\n",
    "    q_hat = recon[:,:q.shape[1]] \n",
    "    x_hat = recon[:,q.shape[1]:].reshape(x.shape) \n",
    "    \n",
    "    return x_hat, q_hat\n",
    "\n",
    "def joint_pca_latents(n_components):\n",
    "    combined_data = torch.cat((q,x.reshape((x.shape[0],-1))),1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reconstruction(\n",
    "    joint_pca_reconstruct(n_components=3)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
