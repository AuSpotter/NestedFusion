{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from formats import experiment_pb2\n",
    "from formats import  quantification_pb2\n",
    "\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, ChainDataset\n",
    "\n",
    "\n",
    "import os\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer.autoguide.guides import AutoDiagonalNormal\n",
    "import pyro.distributions.constraints as constraints\n",
    "from tqdm import trange\n",
    "\n",
    "import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_radius_px = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    }
   ],
   "source": [
    "import data\n",
    "dataset = data.get_dataset(local_radius_px=local_radius_px)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import models\n",
    "reload(models)\n",
    "from models import FusionModel, SeparableVAE, JointVAE, NaiveFusionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recon(x_hat,q_hat, x, q):\n",
    "    x_flat = x.reshape(-1,x.shape[-1])\n",
    "    x_hat = x_hat.reshape(-1,x.shape[-1])\n",
    "\n",
    "    x_mean = x_flat.mean(0)\n",
    "    x_ssr = (x_flat - x_hat).pow(2).sum()\n",
    "    x_sst = (x_flat - x_mean).pow(2).sum()\n",
    "    x_r2 = 1 - x_ssr/x_sst\n",
    "\n",
    "    q_mean = q.mean(0)\n",
    "    q_ssr = (q - q_hat).pow(2).sum()\n",
    "    q_sst = (q - q_mean).pow(2).sum()\n",
    "    q_r2 = 1 - q_ssr/q_sst\n",
    "\n",
    "    return x_r2.item(),q_r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(z,c,m,h=64,d=16,r=5,dir='models'):\n",
    "    model = torch.load(f'{dir}/{m.__name__}-z-{z}-c-{c}-h-{h}-d-{d}-r-{r}.pt').eval().to(device)    \n",
    "    x , q = [], []\n",
    "    # c, z = [], []\n",
    "    x_hat, q_hat = [], []\n",
    "    for batch_x,batch_q in tqdm(data_loader,total=1+(len(dataset)//512),leave=False):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_q = batch_q.to(device)\n",
    "        # batch_c, batch_z = model.encode(batch_x,batch_q)\n",
    "        batch_x_hat,  batch_q_hat = model.reconstruct(batch_x,batch_q)\n",
    "        x.append(batch_x.cpu())\n",
    "        q.append(batch_q.cpu())\n",
    "        # c.append(batch_c.cpu())\n",
    "        # z.append(batch_z.cpu())\n",
    "        x_hat.append(batch_x_hat.detach().cpu())\n",
    "        q_hat.append(batch_q_hat.detach().cpu())\n",
    "\n",
    "    x = torch.cat(x,dim=0).detach().cpu()\n",
    "    q = torch.cat(q,dim=0).detach().cpu()\n",
    "    # c = torch.cat(c,dim=0).detach().cpu()\n",
    "    # z = torch.cat(z,dim=0).detach().cpu()\n",
    "    x_hat = torch.cat(x_hat,dim=0).detach().cpu()\n",
    "    q_hat = torch.cat(q_hat,dim=0).detach().cpu()\n",
    "\n",
    "    return eval_recon(x_hat,q_hat,x, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:57<00:00, 46.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionModel-z-1     :   (0.7524834871292114, 0.3602079153060913)\n",
      "FusionModel-z-2     :   (0.9462422728538513, 0.9414879679679871)\n",
      "FusionModel-z-3     :   (0.973613440990448, 0.9870474338531494)\n",
      "JointVAE-z-1     :   (0.6342923641204834, 0.5894248485565186)\n",
      "JointVAE-z-2     :   (0.7534908056259155, 0.7549608945846558)\n",
      "JointVAE-z-3     :   (0.8179486989974976, 0.7550475597381592)\n",
      "NaiveFusionModel-z-1     :   (0.8843056559562683, 0.6285606622695923)\n",
      "NaiveFusionModel-z-2     :   (0.9404465556144714, 0.9001126289367676)\n",
      "NaiveFusionModel-z-3     :   (0.984740138053894, 0.9292274713516235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,batch_size=512)\n",
    "z_values = [1,2,3]\n",
    "c_values = [1]\n",
    "model_types = [FusionModel, JointVAE, NaiveFusionModel] \n",
    "eval_results= dict()\n",
    "for model_type, z,c in tqdm(list(itertools.product(model_types, z_values,c_values))):\n",
    "    model_label = f'{model_type.__name__}-z-{z}'\n",
    "    eval_results[model_label] = eval_model(z,c,model_type,dir='models',h=64,d=16)\n",
    "for k in eval_results:\n",
    "    print(f'{k}     :   {eval_results[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:30<00:00, 43.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionModel-z-1     :   (0.8825869560241699, 0.9239256381988525)\n",
      "FusionModel-z-2     :   (0.9650605320930481, 0.9836743474006653)\n",
      "FusionModel-z-3     :   (0.9734076857566833, 0.9924401640892029)\n",
      "JointVAE-z-1     :   (0.5275089740753174, 0.46742624044418335)\n",
      "JointVAE-z-2     :   (0.8085591197013855, 0.8625675439834595)\n",
      "JointVAE-z-3     :   (0.8366358280181885, 0.9295810461044312)\n",
      "NaiveFusionModel-z-1     :   (0.892959713935852, 0.8058578968048096)\n",
      "NaiveFusionModel-z-2     :   (0.9811556339263916, 0.754331111907959)\n",
      "NaiveFusionModel-z-3     :   (0.9920786023139954, 0.8786454200744629)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,batch_size=512)\n",
    "z_values = [1,2,3]\n",
    "c_values = [1]\n",
    "model_types = [FusionModel, JointVAE, NaiveFusionModel] \n",
    "eval_results= dict()\n",
    "for model_type, z,c in tqdm(list(itertools.product(model_types, z_values,c_values))):\n",
    "    model_label = f'{model_type.__name__}-z-{z}'\n",
    "    eval_results[model_label] = eval_model(z,c,model_type,dir='models',h=256,d=4)\n",
    "for k in eval_results:\n",
    "    print(f'{k}     :   {eval_results[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 204.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap-2     :   (0.013467013835906982, 0.6193883419036865)\n",
      "umap-3     :   (0.6068850159645081, 0.3506179451942444)\n",
      "umap-concat-2     :   (0.9585246443748474, 0.9579919576644897)\n",
      "umap-concat-3     :   (0.9858996868133545, 0.9693862199783325)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results= dict()\n",
    "model_types = ['umap', 'umap-concat']\n",
    "z_values = [2,3]\n",
    "for model_type, z, in tqdm(list(itertools.product(model_types, z_values))):\n",
    "    path = f'models/{model_type}-z-{z}.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        umap_values = pickle.load(f)\n",
    "    eval_results[f'{model_type}-{z}'] = eval_recon(torch.Tensor(umap_values['x_hat']),torch.Tensor(umap_values['q_hat']),torch.Tensor(umap_values['x']),torch.Tensor(umap_values['q']))\n",
    "\n",
    "for k in eval_results:\n",
    "    print(f'{k}     :   {eval_results[k]}')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
